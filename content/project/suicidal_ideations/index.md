---
title: Identifying Suicidal Ideations
summary: This study presents a comprehensive approach to analyze the user-generated textual contents on social media that reflect suicidal ideas. 

tags:
  - Machine Learning
  - Healthcare
  - Explainable AI
  - Deep Learning
  - Natural Language Processing

date: '2025-09-02T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: Step-by-step procedures for identifying suicidal ideations from the user statements.
  focal_point: Smart

# links:
#   - icon: twitter
#     icon_pack: fab
#     name: Follow
#     url: https://twitter.com/georgecushen
url_code: ''
url_pdf: 'https://www.sciencedirect.com/science/article/pii/S1568494625011263'
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ''
---

For identifying the underlying topics that express suicidal ideations, this study has employed the Latent Dirichlet Allocation (LDA) model. Semantic Network Analysis (SNA) is used to gain a deeper quantitative and qualitative insight into these texts. Besides, an exploratory investigation of different deep learning (DL) models has been performed to identify the posts speculating suicidal ideations. Furthermore, this study has integrated Explainable AI (XAI) techniques like Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP) to enhance interpretability of the decisions taken by the DL models. Techniques like LDA and SNA offer a better understanding of the linguistic features of the suicidal posts, while the integration of the XAI techniques with the DL models elevates the transparency of their decisions.